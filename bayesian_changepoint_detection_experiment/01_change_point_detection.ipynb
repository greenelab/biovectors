{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Point Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to perform bayesian change point detection on each individual token.\n",
    "This method provides probability estimates that a changepoint occurred at a given time point.\n",
    "There may be a problem with detecting changes at the extreme ends of the time series but inconclusive at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:38:40.675263Z",
     "start_time": "2022-01-07T20:38:39.749812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use scipy logsumexp().\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "import plydata as ply\n",
    "import plydata.tidy as ply_tdy\n",
    "import tqdm\n",
    "\n",
    "import bayesian_changepoint_detection.offline_changepoint_detection as offcd\n",
    "from detecta import detect_cusum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:38:40.680696Z",
     "start_time": "2022-01-07T20:38:40.676681Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(\"output/all_tok_frequencies.tsv.xz\").exists():\n",
    "    data = []\n",
    "    for model in tqdm.tqdm(\n",
    "        sorted(\n",
    "            list(Path(\"../multi_model_experiment/output/models\").rglob(\"*/*_0.model\"))\n",
    "        )\n",
    "    ):\n",
    "        wv_model = Word2Vec.load(str(model))\n",
    "        word_freq_df = pd.DataFrame.from_records(\n",
    "            [\n",
    "                {\n",
    "                    \"tok\": re.escape(tok),\n",
    "                    \"word_count\": wv_model.wv.get_vecattr(tok, \"count\"),\n",
    "                    \"year\": re.search(r\"(\\d+)_0\", str(model)).group(1),\n",
    "                }\n",
    "                for tok in wv_model.wv.index_to_key\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        total_count = (word_freq_df >> ply.pull(\"word_count\")).sum()\n",
    "\n",
    "        word_freq_df = word_freq_df >> ply.define(frequency=f\"word_count/{total_count}\")\n",
    "\n",
    "        data.append(word_freq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:38:56.151775Z",
     "start_time": "2022-01-07T20:38:40.682407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danich1/anaconda3/envs/biovectors/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3156: DtypeWarning: Columns (1,2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3744412, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>word_count</th>\n",
       "      <th>year</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\</td>\n",
       "      <td>87283</td>\n",
       "      <td>2000</td>\n",
       "      <td>8.850373e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>38877</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.942073e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>35677</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.617598e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>33131</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.359437e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\.</td>\n",
       "      <td>32263</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.271423e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556728</th>\n",
       "      <td>1\\-ethynyladamantanes</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.285818e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556729</th>\n",
       "      <td>1800\\-fold</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.285818e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556730</th>\n",
       "      <td>foveally</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.285818e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556731</th>\n",
       "      <td>0\\.45x:12\\.79</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.285818e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556732</th>\n",
       "      <td>0\\.29x:8\\.53</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.285818e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8556725 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tok  word_count  year     frequency\n",
       "0                           \\        87283  2000  8.850373e-02\n",
       "1                          the       38877  2000  3.942073e-02\n",
       "2                           of       35677  2000  3.617598e-02\n",
       "3                            ,       33131  2000  3.359437e-02\n",
       "4                           \\.       32263  2000  3.271423e-02\n",
       "...                        ...         ...   ...           ...\n",
       "8556728  1\\-ethynyladamantanes           1  2020  1.285818e-08\n",
       "8556729             1800\\-fold           1  2020  1.285818e-08\n",
       "8556730               foveally           1  2020  1.285818e-08\n",
       "8556731          0\\.45x:12\\.79           1  2020  1.285818e-08\n",
       "8556732           0\\.29x:8\\.53           1  2020  1.285818e-08\n",
       "\n",
       "[8556725 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not Path(\"output/all_tok_frequencies.tsv.xz\").exists():\n",
    "    all_word_freq_df = pd.concat(data) >> ply.call(\".dropna\")\n",
    "    (\n",
    "        all_word_freq_df\n",
    "        >> ply.call(\".dropna\")\n",
    "        >> ply.query(\"year != ''\")\n",
    "        >> ply.call(\".astype\", {\"year\": int, \"frequency\": float, \"word_count\": int})\n",
    "        >> ply.call(\n",
    "            \".to_csv\",\n",
    "            \"output/all_tok_frequencies.tsv.xz\",\n",
    "            sep=\"\\t\",\n",
    "            index=False,\n",
    "            compression=\"xz\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "else:\n",
    "    all_word_freq_df = (\n",
    "        pd.read_csv(\"output/all_tok_frequencies.tsv.xz\", sep=\"\\t\", na_filter=False)\n",
    "        >> ply.call(\".dropna\")\n",
    "        >> ply.query(\"year != ''\")\n",
    "        >> ply.call(\".astype\", {\"year\": int, \"frequency\": float, \"word_count\": int})\n",
    "    )\n",
    "\n",
    "print((all_word_freq_df >> ply.select(\"tok\") >> ply.distinct()).shape)\n",
    "all_word_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:38:56.155340Z",
     "start_time": "2022-01-07T20:38:56.153024Z"
    }
   },
   "outputs": [],
   "source": [
    "# plydata implicitly groups datapoints\n",
    "# need to revert to pandas to actually cycle through each group\n",
    "token_group = all_word_freq_df >> ply.call(\".groupby\", \"tok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:39:01.879327Z",
     "start_time": "2022-01-07T20:38:56.156553Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(\"output/token_frequency_dict.pkl\").exists():\n",
    "    all_token_map = dict()\n",
    "    for tok, group in tqdm.tqdm(token_group):\n",
    "        all_token_map[tok] = group >> ply.arrange(\"year\") >> ply.pull(\"year\")\n",
    "\n",
    "    pickle.dump(all_token_map, open(\"output/token_frequency_dict.pkl\", \"wb\"))\n",
    "else:\n",
    "    all_token_map = pickle.load(open(\"output/token_frequency_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:39:11.179211Z",
     "start_time": "2022-01-07T20:39:01.880561Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3744412/3744412 [00:09<00:00, 402887.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleared_token_map = {\n",
    "    tok: all_token_map[tok]\n",
    "    for tok in tqdm.tqdm(all_token_map)\n",
    "    if len(all_token_map[tok]) > 1\n",
    "    and np.diff(all_token_map[tok]).sum() == len(all_token_map[tok]) - 1\n",
    "}\n",
    "print(len(cleared_token_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate frequency ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:44:10.379552Z",
     "start_time": "2022-01-07T20:39:11.180429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201962, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>word_count</th>\n",
       "      <th>year</th>\n",
       "      <th>frequency</th>\n",
       "      <th>frequency_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55842</th>\n",
       "      <td>traditionally</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.557732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55837</th>\n",
       "      <td>omental</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.478056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55834</th>\n",
       "      <td>418</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.836598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55833</th>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.304218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55830</th>\n",
       "      <td>\\-b</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.836598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tok  word_count       year  frequency  frequency_ratio\n",
       "55842  traditionally           4  2000-2001   0.000003         0.557732\n",
       "55837        omental           4  2000-2001   0.000003         0.478056\n",
       "55834            418           4  2000-2001   0.000003         0.836598\n",
       "55833            175           4  2000-2001   0.000003         0.304218\n",
       "55830            \\-b           4  2000-2001   0.000003         0.836598"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_frequency_ratio_df = (\n",
    "    all_word_freq_df\n",
    "    >> ply.query(f\"tok in {list(cleared_token_map.keys())}\")\n",
    "    >> ply.group_by(\"tok\")\n",
    "    >> ply.arrange(\"year\")\n",
    "    >> ply.define(\n",
    "        frequency_ratio=lambda x: x.frequency / x.shift(1).frequency,\n",
    "    )\n",
    "    >> ply.ungroup()\n",
    "    >> ply.call(\".dropna\")\n",
    "    >> ply.define(year=lambda x: x[\"year\"].apply(lambda y: f\"{y-1}-{y}\"))\n",
    ")\n",
    "print((all_word_frequency_ratio_df >> ply.select(\"tok\") >> ply.distinct()).shape)\n",
    "all_word_frequency_ratio_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab semantic change values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:44:10.384511Z",
     "start_time": "2022-01-07T20:44:10.381468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "distance_files = list(\n",
    "    Path(\"../multi_model_experiment/output/combined_inter_intra_distances\").rglob(\n",
    "        \"saved_*_distance.tsv\"\n",
    "    )\n",
    ")\n",
    "print(len(distance_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:44:12.236221Z",
     "start_time": "2022-01-07T20:44:10.385817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.93it/s]\n"
     ]
    }
   ],
   "source": [
    "year_distance_map = {\n",
    "    re.search(r\"\\d+\", str(year_file)).group(0): (\n",
    "        pd.read_csv(str(year_file), sep=\"\\t\", na_filter=False)\n",
    "    )\n",
    "    for year_file in tqdm.tqdm(distance_files)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:44:20.402718Z",
     "start_time": "2022-01-07T20:44:12.237364Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 48072.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327733, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>original_global_distance</th>\n",
       "      <th>global_distance_qst</th>\n",
       "      <th>ratio_metric</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly\\(adp</td>\n",
       "      <td>0.208324</td>\n",
       "      <td>0.499768</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partners</td>\n",
       "      <td>0.140676</td>\n",
       "      <td>0.467454</td>\n",
       "      <td>0.877771</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>permeation</td>\n",
       "      <td>0.188546</td>\n",
       "      <td>0.513674</td>\n",
       "      <td>1.056235</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>0.283853</td>\n",
       "      <td>0.557411</td>\n",
       "      <td>1.259432</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sixty</td>\n",
       "      <td>0.137166</td>\n",
       "      <td>0.468312</td>\n",
       "      <td>0.880801</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tok  original_global_distance  global_distance_qst  ratio_metric  \\\n",
       "0   poly\\(adp                  0.208324             0.499768      0.999074   \n",
       "1    partners                  0.140676             0.467454      0.877771   \n",
       "2  permeation                  0.188546             0.513674      1.056235   \n",
       "3         137                  0.283853             0.557411      1.259432   \n",
       "4       sixty                  0.137166             0.468312      0.880801   \n",
       "\n",
       "        year  \n",
       "0  2013-2014  \n",
       "1  2013-2014  \n",
       "2  2013-2014  \n",
       "3  2013-2014  \n",
       "4  2013-2014  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_token_set_df = (\n",
    "    pd.concat([year_distance_map[year] for year in tqdm.tqdm(year_distance_map)])\n",
    "    >> ply.define(tok=lambda x: x.tok.apply(lambda y: re.escape(y)))\n",
    "    >> ply_tdy.unite(\"year\", \"year_1\", \"year_2\", sep=\"-\")\n",
    ")\n",
    "print((full_token_set_df >> ply.select(\"tok\") >> ply.distinct()).shape)\n",
    "full_token_set_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:51:19.078583Z",
     "start_time": "2022-01-07T20:44:20.403978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 327733/327733 [06:55<00:00, 788.04it/s]\n"
     ]
    }
   ],
   "source": [
    "freq_map = dict()\n",
    "for tok, group in tqdm.tqdm(full_token_set_df.groupby(\"tok\")):\n",
    "    freq_map[tok] = group >> ply.arrange(\"year\") >> ply.pull(\"ratio_metric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an idea similar to SCAF \\[[1](https://doi.org/10.1007/s00799-019-00271-6)\\], I'm combining the global qst metric with the percent change in frequency.\n",
    "SCAF uses percent change for both metrics; however, the caveat is that their method loses information for the first two timepoints.\n",
    "In my case given that global_distance_qst is a metric that's bound between 0 and 1 frequency percent change can be used directly.\n",
    "By combining these two terms I can use this metric as a means to estimate change and allow for bayesian changepoint detection to calculate the probability of a timepoint change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:56:21.370372Z",
     "start_time": "2022-01-07T20:51:19.079865Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201962/201962 [05:00<00:00, 672.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80513\n"
     ]
    }
   ],
   "source": [
    "data_rows = list()\n",
    "for tok, group in tqdm.tqdm(all_word_frequency_ratio_df.groupby(\"tok\")):\n",
    "    if tok in freq_map and tok != \"null\":\n",
    "        data_rows.append(\n",
    "            {\n",
    "                \"ratio_metric\": (freq_map[tok]),\n",
    "                \"frequency_ratio\": (\n",
    "                    group >> ply.arrange(\"year\") >> ply.pull(\"frequency_ratio\")\n",
    "                ),\n",
    "                \"year\": (group >> ply.arrange(\"year\") >> ply.pull(\"year\")),\n",
    "                \"tok\": [tok]\n",
    "                * (group >> ply.arrange(\"year\") >> ply.pull(\"year\")).shape[0],\n",
    "            }\n",
    "        )\n",
    "print(len(data_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:57:01.573608Z",
     "start_time": "2022-01-07T20:56:21.371685Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_metric</th>\n",
       "      <th>frequency_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.250108</td>\n",
       "      <td>1.003918</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.685207</td>\n",
       "      <td>0.864842</td>\n",
       "      <td>2001-2002</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.333010</td>\n",
       "      <td>0.646562</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.749069</td>\n",
       "      <td>2.505442</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.092308</td>\n",
       "      <td>1.427221</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.347119</td>\n",
       "      <td>3.111310</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>zyxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.345246</td>\n",
       "      <td>0.266405</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>zyxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.304166</td>\n",
       "      <td>1.725867</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>zyxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.353653</td>\n",
       "      <td>0.745896</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>zyxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.167203</td>\n",
       "      <td>1.247680</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>zzw\\-115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843658 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ratio_metric  frequency_ratio       year       tok\n",
       "0       2.250108         1.003918  2000-2001         !\n",
       "1       1.685207         0.864842  2001-2002         !\n",
       "2       2.333010         0.646562  2002-2003         !\n",
       "3       1.749069         2.505442  2003-2004         !\n",
       "4       3.092308         1.427221  2004-2005         !\n",
       "..           ...              ...        ...       ...\n",
       "16      1.347119         3.111310  2016-2017     zyxin\n",
       "17      1.345246         0.266405  2017-2018     zyxin\n",
       "18      1.304166         1.725867  2018-2019     zyxin\n",
       "19      1.353653         0.745896  2019-2020     zyxin\n",
       "0       1.167203         1.247680  2019-2020  zzw\\-115\n",
       "\n",
       "[843658 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_token_df = pd.concat([pd.DataFrame.from_dict(data) for data in data_rows])\n",
    "final_token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:57:01.758160Z",
     "start_time": "2022-01-07T20:57:01.574886Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80513, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>ratio_metric</th>\n",
       "      <th>year_pair</th>\n",
       "      <th>frequency_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>2.250108</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>1.003918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>1.685207</td>\n",
       "      <td>2001-2002</td>\n",
       "      <td>0.864842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>2.333010</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>0.646562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!</td>\n",
       "      <td>1.749069</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>2.505442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!</td>\n",
       "      <td>3.092308</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>1.427221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zyxin</td>\n",
       "      <td>1.347119</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>3.111310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zyxin</td>\n",
       "      <td>1.345246</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>0.266405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zyxin</td>\n",
       "      <td>1.304166</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>1.725867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>zyxin</td>\n",
       "      <td>1.353653</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>0.745896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzw\\-115</td>\n",
       "      <td>1.167203</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>1.247680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843658 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tok  ratio_metric  year_pair  frequency_ratio\n",
       "0          !      2.250108  2000-2001         1.003918\n",
       "1          !      1.685207  2001-2002         0.864842\n",
       "2          !      2.333010  2002-2003         0.646562\n",
       "3          !      1.749069  2003-2004         2.505442\n",
       "4          !      3.092308  2004-2005         1.427221\n",
       "..       ...           ...        ...              ...\n",
       "16     zyxin      1.347119  2016-2017         3.111310\n",
       "17     zyxin      1.345246  2017-2018         0.266405\n",
       "18     zyxin      1.304166  2018-2019         1.725867\n",
       "19     zyxin      1.353653  2019-2020         0.745896\n",
       "0   zzw\\-115      1.167203  2019-2020         1.247680\n",
       "\n",
       "[843658 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_frequency_df = (\n",
    "    final_token_df\n",
    "    >> ply.rename(year_pair=\"year\")\n",
    "    >> ply.select(\n",
    "        \"tok\",\n",
    "        \"ratio_metric\",\n",
    "        \"year_pair\",\n",
    "        \"frequency_ratio\",\n",
    "    )\n",
    ")\n",
    "print((merged_frequency_df >> ply.select(\"tok\") >> ply.distinct()).shape)\n",
    "merged_frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:58:39.626396Z",
     "start_time": "2022-01-07T20:57:01.759175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_pair</th>\n",
       "      <th>tok</th>\n",
       "      <th>ratio_metric</th>\n",
       "      <th>frequency_ratio</th>\n",
       "      <th>change_metric_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-2001</td>\n",
       "      <td>!</td>\n",
       "      <td>2.250108</td>\n",
       "      <td>1.003918</td>\n",
       "      <td>3.254026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-2001</td>\n",
       "      <td>drop</td>\n",
       "      <td>2.380378</td>\n",
       "      <td>0.988707</td>\n",
       "      <td>3.369085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-2001</td>\n",
       "      <td>cfu</td>\n",
       "      <td>1.886854</td>\n",
       "      <td>0.717084</td>\n",
       "      <td>2.603938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-2001</td>\n",
       "      <td>interaction</td>\n",
       "      <td>1.765145</td>\n",
       "      <td>0.851699</td>\n",
       "      <td>2.616845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-2001</td>\n",
       "      <td>m2</td>\n",
       "      <td>2.155668</td>\n",
       "      <td>1.055401</td>\n",
       "      <td>3.211069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-2020</td>\n",
       "      <td>th17\\)/regulatory</td>\n",
       "      <td>1.186573</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>1.966373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-2020</td>\n",
       "      <td>th17</td>\n",
       "      <td>1.052309</td>\n",
       "      <td>0.947320</td>\n",
       "      <td>1.999629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-2020</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>1.356828</td>\n",
       "      <td>0.371333</td>\n",
       "      <td>1.728161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-2020</td>\n",
       "      <td>ligamentum</td>\n",
       "      <td>1.139380</td>\n",
       "      <td>0.995490</td>\n",
       "      <td>2.134869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-2020</td>\n",
       "      <td>zzw\\-115</td>\n",
       "      <td>1.167203</td>\n",
       "      <td>1.247680</td>\n",
       "      <td>2.414883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>843658 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_pair                tok  ratio_metric  frequency_ratio  \\\n",
       "0   2000-2001                  !      2.250108         1.003918   \n",
       "0   2000-2001               drop      2.380378         0.988707   \n",
       "0   2000-2001                cfu      1.886854         0.717084   \n",
       "0   2000-2001        interaction      1.765145         0.851699   \n",
       "0   2000-2001                 m2      2.155668         1.055401   \n",
       "..        ...                ...           ...              ...   \n",
       "0   2019-2020  th17\\)/regulatory      1.186573         0.779800   \n",
       "13  2019-2020               th17      1.052309         0.947320   \n",
       "19  2019-2020            ruffles      1.356828         0.371333   \n",
       "15  2019-2020         ligamentum      1.139380         0.995490   \n",
       "0   2019-2020           zzw\\-115      1.167203         1.247680   \n",
       "\n",
       "    change_metric_ratio  \n",
       "0              3.254026  \n",
       "0              3.369085  \n",
       "0              2.603938  \n",
       "0              2.616845  \n",
       "0              3.211069  \n",
       "..                  ...  \n",
       "0              1.966373  \n",
       "13             1.999629  \n",
       "19             1.728161  \n",
       "15             2.134869  \n",
       "0              2.414883  \n",
       "\n",
       "[843658 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_metric_df = (\n",
    "    merged_frequency_df\n",
    "    >> ply.group_by(\"tok\")\n",
    "    >> ply.arrange(\"year_pair\")\n",
    "    >> ply.define(\n",
    "        change_metric_ratio=\"ratio_metric + frequency_ratio\",\n",
    "    )\n",
    "    >> ply.ungroup()\n",
    "    >> ply.select(\n",
    "        \"year_pair\", \"tok\", \"ratio_metric\", \"frequency_ratio\", \"change_metric_ratio\"\n",
    "    )\n",
    ")\n",
    "change_metric_df >> ply.call(\n",
    "    \".to_csv\", \"output/change_metric_abstracts.tsv\", sep=\"\\t\", index=False\n",
    ")\n",
    "change_metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change point detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Semantic Change Analysis with Frequency (SCAF) to perform bayesian change point detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:58:39.637090Z",
     "start_time": "2022-01-07T20:58:39.629796Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not Path(\"output/bayesian_changepoint_data_abstracts.tsv\").exists():\n",
    "    change_point_results = []\n",
    "    for tok, tok_series_df in tqdm.tqdm(change_metric_df.groupby(\"tok\")):\n",
    "\n",
    "        change_metric_ratio = tok_series_df >> ply.pull(\"change_metric_ratio\")\n",
    "        Q, P, Pcp = offcd.offline_changepoint_detection(\n",
    "            change_metric_ratio,\n",
    "            partial(offcd.const_prior, l=(len(change_metric_ratio) + 1)),\n",
    "            offcd.gaussian_obs_log_likelihood,\n",
    "            truncate=-40,\n",
    "        )\n",
    "        estimated_changepoint_probability = np.exp(Pcp).sum(0)\n",
    "\n",
    "        change_point_results.append(\n",
    "            pd.DataFrame.from_dict(\n",
    "                {\n",
    "                    \"tok\": [tok] * len(estimated_changepoint_probability),\n",
    "                    \"changepoint_prob\": estimated_changepoint_probability,\n",
    "                    \"year_pair\": (\n",
    "                        tok_series_df\n",
    "                        >> ply.select(\"year_pair\")\n",
    "                        >> ply.call(\".shift\", -1)\n",
    "                        >> ply.call(\".dropna\")\n",
    "                        >> ply.pull(\"year_pair\")\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:58:40.036865Z",
     "start_time": "2022-01-07T20:58:39.638925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>changepoint_prob</th>\n",
       "      <th>year_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>2001-2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>2002-2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>2003-2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>2004-2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!</td>\n",
       "      <td>0.182222</td>\n",
       "      <td>2005-2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tok  changepoint_prob  year_pair\n",
       "0   !          0.004488  2001-2002\n",
       "1   !          0.004065  2002-2003\n",
       "2   !          0.002007  2003-2004\n",
       "3   !          0.003899  2004-2005\n",
       "4   !          0.182222  2005-2006"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not Path(\"output/bayesian_changepoint_data_abstracts.tsv\", sep=\"\\t\").exists():\n",
    "    change_point_df = pd.concat(change_point_results)\n",
    "    change_point_df.to_csv(\n",
    "        \"output/bayesian_changepoint_data_abstracts.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "else:\n",
    "    change_point_df = pd.read_csv(\n",
    "        \"output/bayesian_changepoint_data_abstracts.tsv\", sep=\"\\t\"\n",
    "    )\n",
    "change_point_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:58:40.223892Z",
     "start_time": "2022-01-07T20:58:40.038014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>changepoint_prob</th>\n",
       "      <th>year_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>014</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>2014-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639411</th>\n",
       "      <td>sars</td>\n",
       "      <td>0.994003</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>014</td>\n",
       "      <td>0.993782</td>\n",
       "      <td>2012-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>016</td>\n",
       "      <td>0.993016</td>\n",
       "      <td>2016-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348190</th>\n",
       "      <td>h7n9</td>\n",
       "      <td>0.988336</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224053</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>0.981903</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>020</td>\n",
       "      <td>0.980726</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265875</th>\n",
       "      <td>doi:10\\.1186</td>\n",
       "      <td>0.978057</td>\n",
       "      <td>2014-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289640</th>\n",
       "      <td>enzalutamide</td>\n",
       "      <td>0.976665</td>\n",
       "      <td>2013-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262549</th>\n",
       "      <td>distancing</td>\n",
       "      <td>0.972938</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539120</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.965722</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178258</th>\n",
       "      <td>canals</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>2006-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98716</th>\n",
       "      <td>abcc6</td>\n",
       "      <td>0.960018</td>\n",
       "      <td>2015-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520917</th>\n",
       "      <td>oope</td>\n",
       "      <td>0.959267</td>\n",
       "      <td>2016-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222055</th>\n",
       "      <td>converting_enzyme_2</td>\n",
       "      <td>0.958620</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98718</th>\n",
       "      <td>abcc6</td>\n",
       "      <td>0.958432</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432917</th>\n",
       "      <td>liraglutide</td>\n",
       "      <td>0.957343</td>\n",
       "      <td>2009-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>016</td>\n",
       "      <td>0.956610</td>\n",
       "      <td>2014-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309156</th>\n",
       "      <td>fcl</td>\n",
       "      <td>0.956552</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368724</th>\n",
       "      <td>ht1</td>\n",
       "      <td>0.955023</td>\n",
       "      <td>2016-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273435</th>\n",
       "      <td>e\\.coli</td>\n",
       "      <td>0.954467</td>\n",
       "      <td>2005-2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367992</th>\n",
       "      <td>hsaf</td>\n",
       "      <td>0.953965</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195439</th>\n",
       "      <td>chga</td>\n",
       "      <td>0.953347</td>\n",
       "      <td>2010-2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36055</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.953211</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170230</th>\n",
       "      <td>brucella</td>\n",
       "      <td>0.953071</td>\n",
       "      <td>2006-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708073</th>\n",
       "      <td>title</td>\n",
       "      <td>0.949639</td>\n",
       "      <td>2008-2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380693</th>\n",
       "      <td>ilc3</td>\n",
       "      <td>0.948645</td>\n",
       "      <td>2014-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223191</th>\n",
       "      <td>copyright</td>\n",
       "      <td>0.947074</td>\n",
       "      <td>2018-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518419</th>\n",
       "      <td>okara</td>\n",
       "      <td>0.944030</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471975</th>\n",
       "      <td>mmp20</td>\n",
       "      <td>0.943821</td>\n",
       "      <td>2016-2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        tok  changepoint_prob  year_pair\n",
       "2200                    014          0.995481  2014-2015\n",
       "639411                 sars          0.994003  2018-2019\n",
       "2198                    014          0.993782  2012-2013\n",
       "2226                    016          0.993016  2016-2017\n",
       "348190                 h7n9          0.988336  2013-2014\n",
       "224053          coronavirus          0.981903  2018-2019\n",
       "2267                    020          0.980726  2018-2019\n",
       "265875         doi:10\\.1186          0.978057  2014-2015\n",
       "289640         enzalutamide          0.976665  2013-2014\n",
       "262549           distancing          0.972938  2018-2019\n",
       "539120             pandemic          0.965722  2018-2019\n",
       "178258               canals          0.963687  2006-2007\n",
       "98716                 abcc6          0.960018  2015-2016\n",
       "520917                 oope          0.959267  2016-2017\n",
       "222055  converting_enzyme_2          0.958620  2018-2019\n",
       "98718                 abcc6          0.958432  2017-2018\n",
       "432917          liraglutide          0.957343  2009-2010\n",
       "2224                    016          0.956610  2014-2015\n",
       "309156                  fcl          0.956552  2017-2018\n",
       "368724                  ht1          0.955023  2016-2017\n",
       "273435              e\\.coli          0.954467  2005-2006\n",
       "367992                 hsaf          0.953965  2018-2019\n",
       "195439                 chga          0.953347  2010-2011\n",
       "36055                  2020          0.953211  2018-2019\n",
       "170230             brucella          0.953071  2006-2007\n",
       "708073                title          0.949639  2008-2009\n",
       "380693                 ilc3          0.948645  2014-2015\n",
       "223191            copyright          0.947074  2018-2019\n",
       "518419                okara          0.944030  2017-2018\n",
       "471975                mmp20          0.943821  2016-2017"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(change_point_df >> ply.arrange(\"-changepoint_prob\") >> ply.slice_rows(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUSUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses the CUSUM algorithm to determine changepoint events from time series. This algorithm uses a threshold value to determine cutoffs for a changepoint event. To figure out this value I'm using a cutoff of 2 standard deviations from the mean. The mean is calculated after filtering out one outlier that contains a value of 5000 when the other values are 700 and less. This allows for more potential matches to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:58:40.322113Z",
     "start_time": "2022-01-07T20:58:40.225280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_metric_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>843653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.712828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.935849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.623139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.991638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.316084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.898272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>726.176448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       change_metric_ratio\n",
       "count        843653.000000\n",
       "mean              2.712828\n",
       "std               1.935849\n",
       "min               0.623139\n",
       "25%               1.991638\n",
       "50%               2.316084\n",
       "75%               2.898272\n",
       "max             726.176448"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_df = (\n",
    "    change_metric_df\n",
    "    >> ply.query(\"change_metric_ratio < 1000\")\n",
    "    >> ply.select(\"change_metric_ratio\")\n",
    "    >> ply.call(\".describe\")\n",
    ")\n",
    "cutoff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:58:40.327342Z",
     "start_time": "2022-01-07T20:58:40.323440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.503251064958798"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = cutoff_df.loc[\"mean\"] * cutoff_df.loc[\"std\"] * 2\n",
    "threshold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:59:09.768302Z",
     "start_time": "2022-01-07T20:58:40.328624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80513/80513 [00:28<00:00, 2808.16it/s]\n"
     ]
    }
   ],
   "source": [
    "if not Path(\"output/cusum_changepoint_abstracts.tsv\").exists():\n",
    "    change_point_results = []\n",
    "    for tok, tok_series_df in tqdm.tqdm(change_metric_df.groupby(\"tok\")):\n",
    "\n",
    "        change_metric_ratio = tok_series_df >> ply.pull(\"change_metric_ratio\")\n",
    "        year_series = tok_series_df >> ply.pull(\"year_pair\")\n",
    "\n",
    "        alarm, start, end, amp = detect_cusum(\n",
    "            change_metric_ratio,\n",
    "            threshold=threshold[0],\n",
    "            drift=0.5,\n",
    "            ending=True,\n",
    "            show=False,\n",
    "        )\n",
    "\n",
    "        for values in zip(alarm, start, end, amp):\n",
    "\n",
    "            change_point_results.append(\n",
    "                {\n",
    "                    \"tok\": tok,\n",
    "                    \"changepoint_idx\": year_series[values[0]],\n",
    "                    \"start_idx\": year_series[values[1]],\n",
    "                    \"end_idx\": year_series[values[2]],\n",
    "                    \"value\": values[3],\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:59:09.802782Z",
     "start_time": "2022-01-07T20:59:09.769524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2682, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>changepoint_idx</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/5\\-</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>11.948682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/5\\-</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>-11.968209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/disease</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>12.327052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/disease</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>-12.264762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ftc</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>11.435107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>zrc</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>25.106426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>zrc</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>-24.387509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>zu</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>27.577021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>zumba</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>16.246502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>zumba</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>-16.174364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4628 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tok changepoint_idx  start_idx    end_idx      value\n",
       "0         /5\\-       2016-2017  2015-2016  2016-2017  11.948682\n",
       "1         /5\\-       2017-2018  2016-2017  2017-2018 -11.968209\n",
       "2     /disease       2017-2018  2016-2017  2017-2018  12.327052\n",
       "3     /disease       2018-2019  2017-2018  2018-2019 -12.264762\n",
       "4         /ftc       2011-2012  2010-2011  2011-2012  11.435107\n",
       "...        ...             ...        ...        ...        ...\n",
       "4623       zrc       2018-2019  2017-2018  2018-2019  25.106426\n",
       "4624       zrc       2019-2020  2018-2019  2019-2020 -24.387509\n",
       "4625        zu       2019-2020  2018-2019  2019-2020  27.577021\n",
       "4626     zumba       2017-2018  2016-2017  2017-2018  16.246502\n",
       "4627     zumba       2018-2019  2017-2018  2018-2019 -16.174364\n",
       "\n",
       "[4628 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not Path(\"output/cusum_changepoint_abstracts.tsv\").exists():\n",
    "    change_point_df = pd.DataFrame.from_records(change_point_results)\n",
    "    change_point_df >> ply.call(\n",
    "        \".to_csv\", \"output/cusum_changepoint_abstracts.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "else:\n",
    "    change_point_df = pd.read_csv(\"output/cusum_changepoint_abstracts.tsv\", sep=\"\\t\")\n",
    "print((change_point_df >> ply.select(\"tok\") >> ply.distinct()).shape)\n",
    "change_point_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T20:59:09.831086Z",
     "start_time": "2022-01-07T20:59:09.804844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>changepoint_idx</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>014</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>393.790997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10\\.1186</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>347.708598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>016</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>336.462453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>h7n9</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>249.456837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>sars</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>145.519452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>020</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>134.201314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>cas9</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>110.888604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2003</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>99.589218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2004</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>80.950142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>breastfeeding</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>76.576341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>fcl</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>69.488509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>abcc6</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>66.097801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>sarma</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>63.650718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>severe_acute_respiratory_syndrome</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>59.338280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>pcawg</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>59.305922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>54.286120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>agr2</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>54.089358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>oope</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>52.732310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>darolutamide</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>51.701531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>sdab</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>51.526565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>cst1</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>50.680719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>onchocerciasis</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>50.358831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>comanagement</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>50.216471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>distancing</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>47.440880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>phf8</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>45.639422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>chga</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>44.338943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>canals</td>\n",
       "      <td>2005-2006</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>2005-2006</td>\n",
       "      <td>44.282689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>erv1</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>43.827480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>mir\\-450b\\-5p</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>43.776296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>okara</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>2018-2019</td>\n",
       "      <td>43.712966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tok changepoint_idx  start_idx    end_idx  \\\n",
       "10                                  014       2013-2014  2011-2012  2013-2014   \n",
       "22                             10\\.1186       2016-2017  2013-2014  2016-2017   \n",
       "12                                  016       2015-2016  2013-2014  2015-2016   \n",
       "1847                               h7n9       2012-2013  2011-2012  2012-2013   \n",
       "3777                               sars       2019-2020  2018-2019  2019-2020   \n",
       "14                                  020       2019-2020  2017-2018  2019-2020   \n",
       "777                                cas9       2012-2013  2011-2012  2012-2013   \n",
       "48                                 2003       2002-2003  2001-2002  2002-2003   \n",
       "50                                 2004       2003-2004  2001-2002  2003-2004   \n",
       "674                       breastfeeding       2002-2003  2001-2002  2002-2003   \n",
       "1553                                fcl       2016-2017  2015-2016  2016-2017   \n",
       "216                               abcc6       2016-2017  2015-2016  2016-2017   \n",
       "3775                              sarma       2019-2020  2018-2019  2019-2020   \n",
       "3862  severe_acute_respiratory_syndrome       2019-2020  2017-2018  2019-2020   \n",
       "3226                              pcawg       2019-2020  2017-2018  2019-2020   \n",
       "1011                        coronavirus       2019-2020  2018-2019  2019-2020   \n",
       "295                                agr2       2009-2010  2008-2009  2009-2010   \n",
       "3084                               oope       2015-2016  2014-2015  2015-2016   \n",
       "1136                       darolutamide       2018-2019  2017-2018  2018-2019   \n",
       "3808                               sdab       2016-2017  2015-2016  2016-2017   \n",
       "1074                               cst1       2016-2017  2015-2016  2016-2017   \n",
       "3078                     onchocerciasis       2002-2003  2001-2002  2002-2003   \n",
       "987                        comanagement       2019-2020  2018-2019  2019-2020   \n",
       "1258                         distancing       2019-2020  2018-2019  2019-2020   \n",
       "3326                               phf8       2019-2020  2018-2019  2019-2020   \n",
       "883                                chga       2009-2010  2008-2009  2009-2010   \n",
       "743                              canals       2005-2006  2004-2005  2005-2006   \n",
       "1474                               erv1       2019-2020  2018-2019  2019-2020   \n",
       "2687                      mir\\-450b\\-5p       2019-2020  2018-2019  2019-2020   \n",
       "3066                              okara       2018-2019  2017-2018  2018-2019   \n",
       "\n",
       "           value  \n",
       "10    393.790997  \n",
       "22    347.708598  \n",
       "12    336.462453  \n",
       "1847  249.456837  \n",
       "3777  145.519452  \n",
       "14    134.201314  \n",
       "777   110.888604  \n",
       "48     99.589218  \n",
       "50     80.950142  \n",
       "674    76.576341  \n",
       "1553   69.488509  \n",
       "216    66.097801  \n",
       "3775   63.650718  \n",
       "3862   59.338280  \n",
       "3226   59.305922  \n",
       "1011   54.286120  \n",
       "295    54.089358  \n",
       "3084   52.732310  \n",
       "1136   51.701531  \n",
       "3808   51.526565  \n",
       "1074   50.680719  \n",
       "3078   50.358831  \n",
       "987    50.216471  \n",
       "1258   47.440880  \n",
       "3326   45.639422  \n",
       "883    44.338943  \n",
       "743    44.282689  \n",
       "1474   43.827480  \n",
       "2687   43.776296  \n",
       "3066   43.712966  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(change_point_df >> ply.arrange(\"-value\") >> ply.slice_rows(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Home Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bayesian change point detection provides insight on the specific year period a semantic change point may have occurred.\n",
    "2. Best positive result is pandemic which underwent a focus shift from bird flu and influenza to coronavirus.\n",
    "3. Follow up analysis which will appear in the next notebook will involve looking at the top X token neighbors to the query word. By doing that one can estimate which kind of shift a word has undergone."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:biovectors]",
   "language": "python",
   "name": "conda-env-biovectors-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
